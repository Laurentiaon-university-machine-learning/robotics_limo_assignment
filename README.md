# æœºå™¨äººå­¦ä¸è®¡ç®—æœºè§†è§‰è¯¾ç¨‹å®éªŒ | Autonomous Mobile Robotics Course Lab

**ä¸­æ–‡** | [English](#english-version)

## è¯¾ç¨‹æ¦‚è¿° | Course Overview

æœ¬è¯¾ç¨‹å®éªŒé¡¹ç›®ä¸“æ³¨äºæœºå™¨äººè§†è§‰ç³»ç»Ÿçš„è®¾è®¡ä¸å®ç°ï¼Œç»“åˆYOLOç›®æ ‡æ£€æµ‹ã€OpenCVè®¡ç®—æœºè§†è§‰æŠ€æœ¯å’ŒLIMOå°è½¦å¹³å°ï¼Œä¸ºå­¦ç”Ÿæä¾›å®Œæ•´çš„æœºå™¨äººè§†è§‰åº”ç”¨å¼€å‘ä½“éªŒã€‚é€šè¿‡AprilTagäº¤é€šæ ‡å¿—è¯†åˆ«ç³»ç»Ÿçš„å¼€å‘ï¼Œå­¦ç”Ÿå°†æŒæ¡ç°ä»£æœºå™¨äººè§†è§‰ç³»ç»Ÿçš„æ ¸å¿ƒæŠ€æœ¯ã€‚

This course lab project focuses on the design and implementation of robotic vision systems, combining YOLO object detection, OpenCV computer vision technology, and the LIMO robot platform to provide students with a complete robotic vision application development experience.

## å­¦ä¹ ç›®æ ‡ | Learning Objectives

### ç†è®ºçŸ¥è¯† | Theoretical Knowledge
- ğŸ¯ **è®¡ç®—æœºè§†è§‰åŸºç¡€**ï¼šå›¾åƒå¤„ç†ã€ç‰¹å¾æå–ã€ç›®æ ‡æ£€æµ‹åŸç†
- ğŸ§  **æ·±åº¦å­¦ä¹ åº”ç”¨**ï¼šYOLOç›®æ ‡æ£€æµ‹ç®—æ³•çš„ç†è®ºä¸å®è·µ
- ğŸ“ **å‡ ä½•è§†è§‰**ï¼šç›¸æœºæ ‡å®šã€è·ç¦»æµ‹é‡ã€åæ ‡å˜æ¢
- ğŸ¤– **æœºå™¨äººæ„ŸçŸ¥**ï¼šä¼ æ„Ÿå™¨èåˆã€å®æ—¶å†³ç­–ç³»ç»Ÿ

### å®è·µæŠ€èƒ½ | Practical Skills
- ğŸ’» **OpenCVç¼–ç¨‹**ï¼šå›¾åƒå¤„ç†ã€ç‰¹å¾æ£€æµ‹ã€ç›¸æœºæ“ä½œ
- ğŸ” **YOLOæ¨¡å‹éƒ¨ç½²**ï¼šæ¨¡å‹è®­ç»ƒã€ä¼˜åŒ–ã€å®æ—¶æ¨ç†
- ğŸš— **LIMOå°è½¦æ§åˆ¶**ï¼šç¡¬ä»¶æ¥å£ã€è¿åŠ¨æ§åˆ¶ã€ä¼ æ„Ÿå™¨é›†æˆ
- ğŸ·ï¸ **AprilTagç³»ç»Ÿ**ï¼šæ ‡è®°æ£€æµ‹ã€å§¿æ€ä¼°è®¡ã€è·ç¦»æµ‹é‡

## å®éªŒç¯å¢ƒè¦æ±‚ | Environment Requirements

### ç¡¬ä»¶è¦æ±‚ | Hardware Requirements

#### LIMOå°è½¦å¹³å° | LIMO Robot Platform
- **LIMOå››è½®å·®åˆ†æœºå™¨äºº** æˆ– **LIMO Pro**
- **è‹±ç‰¹å°”RealSense D435/D455æ·±åº¦ç›¸æœº** æˆ– **æ™®é€šUSBæ‘„åƒå¤´**
- **Jetson Nano/Xavier NX** æˆ– **æ ‘è“æ´¾4B**ï¼ˆæ¨è4GB+å†…å­˜ï¼‰
- **8GB+å¾®SDå¡**ï¼ˆç”¨äºç³»ç»Ÿå­˜å‚¨ï¼‰
- **å……ç”µå™¨å’Œæ•°æ®çº¿**

#### å®éªŒè¾…åŠ©è®¾å¤‡ | Lab Auxiliary Equipment
- **AprilTagæ ‡è®°å¡ç‰‡**ï¼ˆ8-10cmï¼ŒID: 0-5ï¼‰
- **æµ‹é‡å·¥å…·**ï¼ˆå°ºå­ã€é‡è§’å™¨ï¼‰
- **å®éªŒåœºåœ°**ï¼ˆè‡³å°‘3mÃ—3mçš„å¹³å¦åŒºåŸŸï¼‰
- **è‰¯å¥½ç…§æ˜ç¯å¢ƒ**

### è½¯ä»¶ç¯å¢ƒ | Software Environment

#### åŸºç¡€ç³»ç»Ÿè¦æ±‚ | Basic System Requirements
```bash
# æ”¯æŒçš„æ“ä½œç³»ç»Ÿ | Supported Operating Systems
- Ubuntu 18.04/20.04/22.04 LTS
- Raspberry Pi OS (Bullseye)
- Jetson Nano Developer Kit SD Card Image

# Pythonç‰ˆæœ¬è¦æ±‚ | Python Version Requirements
- Python 3.7+ (æ¨è Python 3.8+)
```

#### æ ¸å¿ƒä¾èµ–åº“ | Core Dependencies
```python
# è®¡ç®—æœºè§†è§‰åº“ | Computer Vision Libraries
opencv-python>=4.7.0          # OpenCVä¸»åº“
opencv-contrib-python>=4.7.0   # OpenCVæ‰©å±•åº“ï¼ˆåŒ…å«ArUcoæ¨¡å—ï¼‰

# æ•°å€¼è®¡ç®—åº“ | Numerical Computing Libraries
numpy>=1.23.0                  # æ•°å€¼è®¡ç®—åŸºç¡€
matplotlib>=3.5.0              # æ•°æ®å¯è§†åŒ–

# å›¾åƒå¤„ç†åº“ | Image Processing Libraries
imutils>=0.5.4                 # OpenCVå·¥å…·é›†
Pillow>=9.0.0                  # å›¾åƒå¤„ç†

# YOLOç›¸å…³ä¾èµ– | YOLO Related Dependencies
ultralytics>=8.0.0            # YOLOv8å®˜æ–¹åº“
torch>=1.12.0                 # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
torchvision>=0.13.0           # PyTorchè§†è§‰åº“

# æœºå™¨äººæ§åˆ¶åº“ | Robot Control Libraries  
rclpy                          # ROS2 Pythonå®¢æˆ·ç«¯ï¼ˆé€‚ç”¨äºROS2ç¯å¢ƒï¼‰
geometry_msgs                  # ROSå‡ ä½•æ¶ˆæ¯
sensor_msgs                    # ROSä¼ æ„Ÿå™¨æ¶ˆæ¯
```

## æŠ€æœ¯æ ˆè¯¦è§£ | Technology Stack Details

### 1. YOLOç›®æ ‡æ£€æµ‹ | YOLO Object Detection

#### YOLOç®—æ³•åŸç† | YOLO Algorithm Principles
```python
# YOLOv8æ¨¡å‹é›†æˆç¤ºä¾‹ | YOLOv8 Model Integration Example
from ultralytics import YOLO

class TrafficSignYOLO:
    def __init__(self, model_path="yolov8n.pt"):
        self.model = YOLO(model_path)
        self.traffic_signs = {
            0: "NO_ENTRY", 1: "DEAD_END", 2: "TURN_RIGHT",
            3: "TURN_LEFT", 4: "FORWARD", 5: "STOP"
        }
    
    def detect_signs(self, frame):
        """ä½¿ç”¨YOLOæ£€æµ‹äº¤é€šæ ‡å¿—"""
        results = self.model(frame)
        detections = []
        
        for r in results:
            boxes = r.boxes
            if boxes is not None:
                for box in boxes:
                    # æå–è¾¹ç•Œæ¡†å’Œç½®ä¿¡åº¦
                    xyxy = box.xyxy[0].cpu().numpy()
                    conf = box.conf[0].cpu().numpy()
                    cls = int(box.cls[0].cpu().numpy())
                    
                    if conf > 0.5:  # ç½®ä¿¡åº¦é˜ˆå€¼
                        detections.append({
                            'bbox': xyxy,
                            'confidence': conf,
                            'class': self.traffic_signs.get(cls, 'UNKNOWN')
                        })
        
        return detections
```

#### YOLOæ¨¡å‹è®­ç»ƒ | YOLO Model Training
```bash
# æ•°æ®é›†å‡†å¤‡ | Dataset Preparation
mkdir -p datasets/traffic_signs/{train,val}/{images,labels}

# æ¨¡å‹è®­ç»ƒå‘½ä»¤ | Model Training Commands
yolo train data=traffic_signs.yaml model=yolov8n.pt epochs=100 imgsz=640

# æ¨¡å‹éªŒè¯ | Model Validation
yolo val model=runs/detect/train/weights/best.pt data=traffic_signs.yaml
```

### 2. OpenCVè®¡ç®—æœºè§†è§‰ | OpenCV Computer Vision

#### å›¾åƒé¢„å¤„ç†ç®¡é“ | Image Preprocessing Pipeline
```python
def enhanced_preprocessing(frame):
    """å¢å¼ºçš„å›¾åƒé¢„å¤„ç†æµç¨‹"""
    # 1. é¢œè‰²ç©ºé—´è½¬æ¢
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # 2. é«˜æ–¯æ¨¡ç³Šé™å™ª
    blurred = cv2.GaussianBlur(gray, (3, 3), 0)
    
    # 3. CLAHEå¯¹æ¯”åº¦å¢å¼º
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(blurred)
    
    # 4. è‡ªé€‚åº”é˜ˆå€¼äºŒå€¼åŒ–
    binary = cv2.adaptiveThreshold(
        enhanced, 255, cv2.ADAPTIVE_THRESH_MEAN_C, 
        cv2.THRESH_BINARY, 11, 7
    )
    
    return {
        'original': gray,
        'blurred': blurred, 
        'enhanced': enhanced,
        'binary': binary
    }
```

#### AprilTagæ£€æµ‹ä¼˜åŒ– | AprilTag Detection Optimization
```python
def setup_apriltag_detector():
    """é…ç½®AprilTagæ£€æµ‹å™¨å‚æ•°"""
    aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_APRILTAG_36h11)
    parameters = cv2.aruco.DetectorParameters()
    
    # é’ˆå¯¹8-10cmæ ‡è®°çš„ä¼˜åŒ–å‚æ•°
    parameters.adaptiveThreshWinSizeMin = 3
    parameters.adaptiveThreshWinSizeMax = 23
    parameters.minMarkerPerimeterRate = 0.02  # å°å°ºå¯¸æ ‡è®°
    parameters.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX
    
    return aruco_dict, parameters
```

### 3. LIMOå°è½¦é›†æˆ | LIMO Robot Integration

#### ROS2é€šä¿¡æ¶æ„ | ROS2 Communication Architecture
```python
import rclpy
from rclpy.node import Node
from geometry_msgs.msg import Twist
from sensor_msgs.msg import Image
from cv_bridge import CvBridge

class LimoVisionController(Node):
    def __init__(self):
        super().__init__('limo_vision_controller')
        
        # å‘å¸ƒå™¨ï¼šè¿åŠ¨æ§åˆ¶
        self.cmd_vel_publisher = self.create_publisher(Twist, '/cmd_vel', 10)
        
        # è®¢é˜…å™¨ï¼šç›¸æœºå›¾åƒ
        self.image_subscription = self.create_subscription(
            Image, '/camera/image_raw', self.image_callback, 10
        )
        
        self.bridge = CvBridge()
        self.yolo_detector = TrafficSignYOLO()
    
    def image_callback(self, msg):
        """å¤„ç†ç›¸æœºå›¾åƒå¹¶æ‰§è¡Œå†³ç­–"""
        try:
            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
            
            # YOLOæ£€æµ‹
            detections = self.yolo_detector.detect_signs(cv_image)
            
            # æ ¹æ®æ£€æµ‹ç»“æœæ§åˆ¶å°è½¦
            self.execute_traffic_sign_action(detections)
            
        except Exception as e:
            self.get_logger().error(f'Image processing error: {e}')
    
    def execute_traffic_sign_action(self, detections):
        """æ ¹æ®äº¤é€šæ ‡å¿—æ‰§è¡Œå¯¹åº”åŠ¨ä½œ"""
        cmd = Twist()
        
        for detection in detections:
            sign_type = detection['class']
            
            if sign_type == 'STOP':
                # åœè½¦3ç§’
                cmd.linear.x = 0.0
                cmd.angular.z = 0.0
                self.get_logger().info('STOP sign detected - stopping for 3 seconds')
                
            elif sign_type == 'TURN_LEFT':
                # å·¦è½¬
                cmd.linear.x = 0.2
                cmd.angular.z = 0.5
                
            elif sign_type == 'TURN_RIGHT':
                # å³è½¬
                cmd.linear.x = 0.2
                cmd.angular.z = -0.5
                
            elif sign_type == 'FORWARD':
                # ç›´è¡Œ
                cmd.linear.x = 0.3
                cmd.angular.z = 0.0
        
        self.cmd_vel_publisher.publish(cmd)
```

## å¿«é€Ÿå¼€å§‹ | Quick Start

### 1. ç¯å¢ƒé…ç½® | Environment Setup

```bash
# å…‹éš†é¡¹ç›® | Clone Repository
git clone https://github.com/your-username/robotics_limo_assignment.git
cd robotics_limo_assignment

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ | Create Virtual Environment
python3 -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate  # Windows

# å®‰è£…ä¾èµ– | Install Dependencies
pip install -r requirements.txt

# éªŒè¯å®‰è£… | Verify Installation
python -c "import cv2, numpy, ultralytics; print('Environment setup successful!')"
```

### 2. LIMOå°è½¦é…ç½® | LIMO Robot Configuration

```bash
# è¿æ¥LIMOå°è½¦ | Connect to LIMO Robot
# æ–¹æ³•1ï¼šWiFiè¿æ¥ï¼ˆæ¨èï¼‰
ssh agilex@192.168.1.100  # é»˜è®¤IPåœ°å€

# æ–¹æ³•2ï¼šä¸²å£è¿æ¥
sudo minicom -D /dev/ttyUSB0 -b 115200

# æ£€æŸ¥LIMOçŠ¶æ€ | Check LIMO Status
rostopic list  # ROS1ç¯å¢ƒ
ros2 topic list  # ROS2ç¯å¢ƒ

# å¯åŠ¨ç›¸æœºèŠ‚ç‚¹ | Start Camera Node
ros2 run usb_cam usb_cam_node_exe --ros-args -p video_device:="/dev/video0"
```

### 3. è¿è¡Œå®éªŒ | Run Experiments

#### å®éªŒ1ï¼šAprilTagæ£€æµ‹ | Experiment 1: AprilTag Detection
```bash
cd assignment1
python CPSC_5207EL_A1_Gx_CV.py

# æ“ä½œè¯´æ˜ | Operation Instructions
# ESC: é€€å‡ºç¨‹åº | Exit program
# S: ä¿å­˜å¤„ç†æ­¥éª¤å›¾åƒ | Save processing steps
# W/D: è°ƒæ•´ç„¦è· | Adjust focal length
# R: é‡ç½®ç„¦è· | Reset focal length
# C: æ ¡å‡†æ¨¡å¼è¯´æ˜ | Calibration instructions
```

#### å®éªŒ2ï¼šYOLO+LIMOé›†æˆ | Experiment 2: YOLO+LIMO Integration
```bash
# å¯åŠ¨ROS2ç¯å¢ƒ | Start ROS2 Environment
source /opt/ros/foxy/setup.bash  # æˆ–å…¶ä»–ROS2ç‰ˆæœ¬

# è¿è¡ŒLIMOæ§åˆ¶èŠ‚ç‚¹ | Run LIMO Control Node
ros2 run limo_vision_pkg limo_vision_controller

# åœ¨æ–°ç»ˆç«¯ä¸­ç›‘æ§è¯é¢˜ | Monitor topics in new terminal
ros2 topic echo /cmd_vel
```

## å®éªŒä»»åŠ¡ | Lab Assignments

### Assignment 1: AprilTagäº¤é€šæ ‡å¿—è¯†åˆ« | AprilTag Traffic Sign Recognition
- **ç›®æ ‡**ï¼šå®ç°åŸºäºAprilTagçš„äº¤é€šæ ‡å¿—æ£€æµ‹ä¸è·ç¦»æµ‹é‡
- **è¦æ±‚**ï¼š
  - æ”¯æŒ6ç§äº¤é€šæ ‡å¿—ç±»å‹è¯†åˆ«
  - å®æ—¶è·ç¦»æµ‹é‡ï¼ˆç²¾åº¦Â±2cmï¼‰
  - å›¾åƒå¤„ç†æµç¨‹å¯è§†åŒ–
  - åŠ¨æ€ç„¦è·æ ¡å‡†åŠŸèƒ½

### Assignment 2: YOLOç›®æ ‡æ£€æµ‹ç³»ç»Ÿ | YOLO Object Detection System
- **ç›®æ ‡**ï¼šå¼€å‘åŸºäºYOLOv8çš„äº¤é€šæ ‡å¿—æ£€æµ‹ç³»ç»Ÿ
- **è¦æ±‚**ï¼š
  - è®­ç»ƒè‡ªå®šä¹‰YOLOæ¨¡å‹
  - å®ç°å®æ—¶æ£€æµ‹ï¼ˆ>10 FPSï¼‰
  - æ£€æµ‹ç²¾åº¦>90%
  - æ”¯æŒå¤šç›®æ ‡åŒæ—¶æ£€æµ‹

### Assignment 3: LIMOå°è½¦è‡ªä¸»å¯¼èˆª | LIMO Autonomous Navigation
- **ç›®æ ‡**ï¼šé›†æˆè§†è§‰ç³»ç»Ÿä¸LIMOå°è½¦ï¼Œå®ç°è‡ªä¸»å¯¼èˆª
- **è¦æ±‚**ï¼š
  - åŸºäºäº¤é€šæ ‡å¿—çš„å†³ç­–ç³»ç»Ÿ
  - å®‰å…¨åœè½¦æœºåˆ¶
  - è·¯å¾„è§„åˆ’ä¸é¿éšœ
  - å®æ—¶çŠ¶æ€ç›‘æ§

## è¯„åˆ†æ ‡å‡† | Grading Criteria

| è¯„ä¼°é¡¹ç›® | æƒé‡ | è¯„åˆ†æ ‡å‡† |
|---------|------|----------|
| **ä»£ç å®ç°** | 40% | ä»£ç è´¨é‡ã€åŠŸèƒ½å®Œæ•´æ€§ã€ç®—æ³•æ­£ç¡®æ€§ |
| **ç³»ç»Ÿæ€§èƒ½** | 25% | æ£€æµ‹ç²¾åº¦ã€å®æ—¶æ€§ã€ç¨³å®šæ€§ |
| **åˆ›æ–°è®¾è®¡** | 20% | ç®—æ³•ä¼˜åŒ–ã€åŠŸèƒ½æ‰©å±•ã€ç”¨æˆ·ä½“éªŒ |
| **å®éªŒæŠ¥å‘Š** | 15% | æŠ€æœ¯æ–‡æ¡£ã€ç»“æœåˆ†æã€é—®é¢˜è§£å†³ |

## å¸¸è§é—®é¢˜è§£å†³ | Troubleshooting

### ç¯å¢ƒé—®é¢˜ | Environment Issues

#### Q1: OpenCVå®‰è£…å¤±è´¥
```bash
# è§£å†³æ–¹æ¡ˆ1ï¼šä½¿ç”¨condaå®‰è£…
conda install -c conda-forge opencv

# è§£å†³æ–¹æ¡ˆ2ï¼šä»æºç ç¼–è¯‘
git clone https://github.com/opencv/opencv.git
cd opencv && mkdir build && cd build
cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local ..
make -j4 && sudo make install
```

#### Q2: LIMOå°è½¦è¿æ¥é—®é¢˜
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
ping 192.168.1.100

# æ£€æŸ¥ä¸²å£æƒé™
sudo usermod -a -G dialout $USER
sudo chmod 666 /dev/ttyUSB0

# é‡å¯ç½‘ç»œæœåŠ¡
sudo systemctl restart NetworkManager
```

### æ€§èƒ½ä¼˜åŒ– | Performance Optimization

#### æé«˜æ£€æµ‹ç²¾åº¦ | Improve Detection Accuracy
- ç¡®ä¿å……è¶³å…‰ç…§æ¡ä»¶
- è°ƒæ•´ç›¸æœºç„¦è·å’Œè§’åº¦
- ä½¿ç”¨é«˜è´¨é‡AprilTagæ ‡è®°
- ä¼˜åŒ–å›¾åƒé¢„å¤„ç†å‚æ•°

#### æå‡è¿è¡Œé€Ÿåº¦ | Improve Running Speed
- é™ä½å›¾åƒåˆ†è¾¨ç‡ï¼ˆå¦‚640Ã—480ï¼‰
- ä½¿ç”¨GPUåŠ é€Ÿï¼ˆCUDAï¼‰
- ä¼˜åŒ–æ£€æµ‹å‚æ•°
- å‡å°‘ä¸å¿…è¦çš„å›¾åƒå¤„ç†æ­¥éª¤

## æ‰©å±•å­¦ä¹  | Extended Learning

### è¿›é˜¶é¡¹ç›® | Advanced Projects
- **å¤šæœºå™¨äººåä½œ**ï¼šå¤šLIMOå°è½¦ååŒå¯¼èˆª
- **SLAMå»ºå›¾**ï¼šåŒæ­¥å®šä½ä¸åœ°å›¾æ„å»º
- **è¯­ä¹‰åˆ†å‰²**ï¼šåœºæ™¯ç†è§£ä¸è·¯å¾„è§„åˆ’
- **å¼ºåŒ–å­¦ä¹ **ï¼šæ™ºèƒ½å†³ç­–ä¸è·¯å¾„ä¼˜åŒ–

### ç›¸å…³è¯¾ç¨‹ | Related Courses
- æœºå™¨å­¦ä¹ ä¸æ·±åº¦å­¦ä¹ 
- æœºå™¨äººæ“ä½œç³»ç»Ÿï¼ˆROSï¼‰
- è®¡ç®—æœºè§†è§‰ç®—æ³•
- è‡ªåŠ¨é©¾é©¶æŠ€æœ¯

## å‚è€ƒèµ„æº | References

### å®˜æ–¹æ–‡æ¡£ | Official Documentation
- [OpenCV Documentation](https://docs.opencv.org/)
- [YOLO Official Repository](https://github.com/ultralytics/ultralytics)
- [ROS2 Documentation](https://docs.ros.org/en/foxy/)
- [LIMO User Manual](https://docs.agilex.ai/)

### å­¦æœ¯è®ºæ–‡ | Academic Papers
- AprilTag: A robust and flexible visual fiducial system
- YOLOv8: Real-time object detection with improved accuracy
- ROS: an open-source Robot Operating System

### åœ¨çº¿æ•™ç¨‹ | Online Tutorials
- [OpenCV Python Tutorials](https://opencv-python-tutroals.readthedocs.io/)
- [Deep Learning for Computer Vision](https://www.coursera.org/learn/convolutional-neural-networks)
- [ROS2 Tutorials](https://docs.ros.org/en/foxy/Tutorials.html)

---

## English Version

### Course Overview
This robotics and computer vision lab course combines YOLO object detection, OpenCV computer vision techniques, and the LIMO robot platform to provide comprehensive hands-on experience in robotic vision systems development.

### Learning Objectives
- Master computer vision fundamentals and deep learning applications
- Develop proficiency in OpenCV programming and YOLO model deployment
- Gain experience with robotic hardware integration and control
- Build real-world autonomous navigation systems

### Technology Stack
- **YOLO**: State-of-the-art object detection for traffic sign recognition
- **OpenCV**: Comprehensive computer vision library for image processing
- **LIMO Robot**: Versatile robot platform for autonomous navigation
- **ROS2**: Robot Operating System for communication and control

### Quick Start Guide
1. **Environment Setup**: Install Python 3.7+, OpenCV 4.7+, and required dependencies
2. **Hardware Configuration**: Connect LIMO robot and camera system
3. **Run Experiments**: Execute AprilTag detection and YOLO integration demos
4. **Advanced Projects**: Develop autonomous navigation and multi-robot systems

For detailed English documentation, please refer to the assignment-specific README files in each subdirectory.

---

## è®¸å¯è¯ | License

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## è´¡çŒ® | Contributing

æ¬¢è¿æäº¤ Issue å’Œ Pull Request æ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ã€‚

Welcome to submit Issues and Pull Requests to improve this project.

## è”ç³»æ–¹å¼ | Contact

å¦‚æœ‰é—®é¢˜ï¼Œè¯·è”ç³»è¯¾ç¨‹åŠ©æ•™æˆ–è®¿é—®é¡¹ç›® GitHub é¡µé¢ã€‚

For questions, please contact the course TAs or visit the project GitHub page.